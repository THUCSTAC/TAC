# 学生评教与课程调研

本章尝试回答下面几个问题：

1. 学生给一些课程的评教打低分、一些课程的评教打高分，这些课程有什么不同？反映学生对课程的哪些**普遍期待**？
2. 我们如何用好教学目标？
3. 我们如何在课程中收集反馈，以了解学生的**具体需求**？
4. 我们如何将学生的需求转换为**可行的课程改进措施**, 从而让学生实际学到更多、课程评教分数更好？

**讲义内容不是线下研讨的主要内容，只是线下研讨的辅助材料/自学材料。**

线下研讨可能涉及这些讨论话题:

1. 同学们倾向于给一节什么样的课打最高/最低的教评分数？反映了对课程的哪些期待？
2. 如何运用课程目标 / 可以如何表述课程目标?
3. 课程调研中需要遵循哪些原则 / 如何制作一份课前调研问卷？
4. 具体的课程改革案例讨论
5. Computing Education Research 文献导读

## A. 学生教评高/低的课程有什么特征？

你可能会觉得，关于“影响评教分数的因素”, 应当有一些研究可供参考。相关研究确实丰富，但对教师来说，值得参考的并没有那么多。

这要从研究的出发点说起。很多关于“评教分数影响因素”的教育学研究，是为了制定更规范严谨的、真实反映教学质量的评教方案，而不是为了帮教师找到改善评教分数的方法。也就是说, 是为了做出更有公信力的评教benchmark, 而不是帮教师对课程做profiling。或者说，学生评教，本身就是为了做benchmark而不是profiling。

??? note "benchmark与profiling"
    如果不熟悉计算机系统领域的术语，这里有一个简单的科普: benchmark通常被称作“测试基准”，是用来比较一系列不同的程序孰优孰劣。profiling通常被称作“性能分析”，是用来对一个特定的程序找到它内部的性能瓶颈、优缺点。通常来说，benchmark能让你理解你的程序比起其他程序，排在第几名。profiling能告诉你，该从哪些具体的方面来优化程序。我们说学生评教更接近于benchmark而非profiling，就是说，它对我们应该如何改进课程，并不会给出特别具体的方向，只是告诉我们“当前课程的教学效果、学习体验，相比其他课程，处在什么相对排名”。

例如这篇研究综述，IDEA Paper No. 50: Student ratings of teaching: A summary of research and literature.(2010), 列举了一些影响学生评教分数的变量: 课程是否必修（选修课里对内容本身感兴趣的同学比较多）, 课程的学科领域（文科课程普遍比理工科评教高），等等。但咱也决定不了自己的课是必修/选修。

这里引用一下这篇综述的结尾部分：
!!! quote "From IDEA Paper No. 50: Student ratings of teaching: A summary of research and literature.(2010)"
    This paper summarizes the general conclusions from the research on student ratings. Whether these conclusions hold true for all contexts is an empirical question. If an institution has reason to believe that these conclusions do not apply, key players should gather local data to address the issue. In the absence of evidence to the contrary, however, the following general conclusions can be used as a guide (Marsh, 2007, p. 372):
    
    SETs [student evaluations of teaching effectiveness] are multidimensional, reliable and stable, primarily a function of the instructor who teaches a course rather than the course that is taught, relatively valid against a variety of indicators of effective teaching, relatively unaffected by a variety of potential biases, and are seen to be useful by faculty, students, and administrators.

    翻译: 本文总结了学生评教相关的研究。这些结论是否普遍适用，是一个实证研究问题。如果某所大学感觉某个结论在那里不适用，管事的人应该收集自己学校的数据来做一些检验。但是，如果拿不出相反的证据，那么下列说法通常是对的:

    学生评教分数是多维的、可靠的、稳定的，主要受到教课程的老师影响，而不是受到课程的影响。和其他关于教学效果的评价方式交叉分析时，学生评教都是相对有效的。和一些可能的扰动变量交叉分析时，学生评教都是相对不受影响的。在教师、学生和教学管理人员眼中，学生评教都是有用的。

大概就是说，我们知道学生评教总体上客观反映了教学质量，统计意义上，学生通常是对的。 如果感觉学校的评教制度有问题，需要在学校收集具体的数据做实证检验。

有一些研究尝试关注“教师做哪些事情能改善评教分数”:

例如这篇研究，McGowan, W. R., & Graham, C. R. (2009). Factors contributing to improved teaching performance. Innovative Higher Education, 34(3), 161-171， 调研了教评分数连续几年有所提升的教师，询问他们采取了哪些改进教学的措施。主要是这三类措施：

1. 让学生的学习更加active和practical, 比如让学生在课上动手实操、小组讨论等等。 
2. 增加各种形式的师生互动, 和学生在课上课下多做交流。
3. 设立清晰的学习产出(Learning Outcomes)、围绕学习目标打造课程，并给学生提出较高的期望。

这些方向看起来都没问题。但是，具体要怎样做？动手实操和小组讨论会不会导致课程讲不完？所有学生都喜欢师生互动吗？学习产出到底是啥？

关于学习产出，确实有一个叫做Outcome-Based Education的教育名词，简称OBE。大概原理是：
 - 首先设计好，这门课能够给学生带来哪几项提升，
 - 把这门课的所有环节（上课、作业、考试）都围绕着让学生获得这些提升来设计
 - 测量学生是否获得了这些提升

看来，我们需要针对我们系的学生，或者某门课上的学生，做一些调研，看看他们是怎么想的。打一个比方，把已有的关于学生教评的研究看做一个大模型，我们需要就要用本地的数据做fine-tune。

（如果有更有针对性的、关于学生教评的研究，欢迎提供给我们）

（我们实际收集了一些访谈数据，不公开，仅在线下研讨时用于讨论）


我们真正想知道的信息是，如果咱们系的学生给一些课程的评教打低分、一些课程的评教打高分，这些课程具体有什么不同？

例如，我们访谈很多学生，请他们描述，自己打教评分数最低的课程，和自己打教评分数最高的课程，分别是什么样子的，获得有启发性的回答。

这样，我们就能找出，课程具备哪些特点会带来更高的评教分数，然后尝试把这些特点添加到课程中。

一些具体的访谈提纲和结果的讨论，请参考[教评好坏的原因](./reasons_of_ratings.md), 但这里不包括原始访谈数据。

??? note "理论研讨: 教学目标与Outcome Based Education"

    一些经典的课程设计理论认为“教学目标”是一切教学设计的出发点，没有清晰的教学目标就没有成功的教学。教师发展中心的“青年教师教学能力进阶项目”有一部分是讲“教学目标的选择和提炼”。 学生对“作业和课堂联系不紧密” “平时作业和考试联系不紧密“的感受，也可以理解为”作业和课堂未能体现出围绕同一个教学目标的清晰联系。“

    “学习产出”和“教学目标”略有不同。关于”学习产出",您可能听说过工程教育专业认证的三大基本理念：成果导向理念、学生中心理念、持续改进理念，相关文献[1,2,3]。

    提出Outcome Based Education这个名词的Williams G Spady，认为 Outcome-based education (OBE) means clearly focusing and organizing everything in an educational system around what is essential for all students to be able to do successfully at the end of their learning experiences. [4]
    
    可以认为，对计算机系来说，Outcome是培养方案里的人才培养目标。对课程来说，Outcome是教学大纲里的教学目标，但是需要把“本课程讲授这些知识”的句式改写为“上课后，学生将能掌握这些知识、具备这些能力”的句式。
    
    像ACM制定的Computing Curricula CC2020中的“胜任力”，也可以认为是计算机专业需要的学习产出(Learning Outcomes).[5] 有些地方认为learning outcome和competency可以互换使用。[6]

    参考文献:
    
    1. 解析工程教育专业认证的成果导向理念. 李志义.中国高等教育,2014
    2. 解析工程教育专业认证的学生中心理念. 李志义.中国高等教育,2014
    3. 解析工程教育专业认证的持续改进理念. 李志义.中国高等教育,2015
    4. Outcome Based Education, William G Spady: https://files.eric.ed.gov/fulltext/ED380910.pdf
    5. 张铭,陈娟.ACM/IEEE CC2020胜任力模型对中国计算机教育发展的影响[J].计算机教育,2023(04):3-8+14.DOI:10.16512/j.cnki.jsjjy.2023.04.019.
    6. https://cset.mnsu.edu/departments/computer-information-science/se/

## B. 如何用好教学目标?

课程教学目标是否明确突出、是否被学生所接受，是影响教评的重要因素之一，所以在这里做一些单独的讨论。

比如, 常见的“课堂讲授和作业脱节”, 解决思路并不是“课程讲授向作业靠拢”或“作业向课堂讲授靠拢”, 而是“课堂讲授和作业都向教学目标靠拢”。如果课程注重实践, 学习目标主要通过作业实现，也可能先围绕教学目标设计好作业，然后再思考学生为了完成作业任务，需要从课堂上学到哪些理论知识, 以此安排课堂教学。

教学目标的一个重要作用, 是“说服学生，这门课值得上、值得投入精力”。一门课的学习目标有很多种不同层次的表述方式, 教师可以灵活地表达:

- “掌握xx知识和yy技能”  “在团队合作能力和问题解决能力上有所成长”
- “提升对xx学科方向的兴趣和自信”   “学完后能胜任xx科研与工程岗位”
- “奠定学习后续xx和yy课程的基础”  “满足院系/学校的xx培养目标”

教师认同的教学目标和学生的学习目标未必一致。要么去说服学生接受这个教学目标，要么就得想办法修改教学目标, 去适应学生的想法。

线下讨论时，我们会讨论 [15-213的教学目标](./15213.md) 写得好在哪里，对我们有什么启发。

另外, 除了整门课程, 单次作业的教学目标有时也很有用。

比如, Stanford CS107 的Assignment2, 就这样陈述了这次作业的学习目标(learning goals), 告诉学生本次作业的收获是什么。

This assignment covers topics in recent string lectures and the second lab. You will be building your skills with:（你将提升下面几方面的能力）

- C-strings (both raw manipulation and using string library functions)
- Viewing Unix utility programs from an internal perspective - as an implementer, not just a client（使用C字符串库，理解unix命令的内部实现）
- Exposure to programmatic access of the filesystem and shell environment variables（尝试使用文件系统和shell环境变量）
- Thoroughly documenting your code, and learning about the importance of good documentation（练习编写文档，了解文档的重要性）

这里举出了几件事情, 可以围绕教学目标来完善课程的设计:

- 尝试列出每一章节、每节课、每次作业的细分教学目标
- 审阅现在的课程设计、作业设计是否和列出的目标一致
- 对每一项教学目标，描述学生需要达到的程度
- 对每一项教学目标，写一写如何考核学生是否达成
- 对不同追求的同学，设置不同层次的教学目标
- 邀请往年选课同学来讲一讲"我从这门课程当中学到了什么"

一些海外学校关于“教学目标”的教学参考资料:

https://teachingcommons.stanford.edu/teaching-guides/foundations-course-design/course-planning/creating-learning-outcomes

https://evals.stanford.edu/end-term-feedback/how-write-learning-goals

https://www.cmu.edu/teaching/designteach/design/learningobjectives.html

## C. 如何收集课程反馈，了解学生的具体需求？

### 收集和使用课程反馈的原则

反馈收集相关(问卷):

- 实名匿名均可，但“看似匿名、后续被实名”是一定要避免的。无论实名还是匿名，都需要合法合规保护学生的个人信息。
- 问卷的问题要减少引导性，让学生汇报更接近“客观事实”的东西，而不是做主观判断。例如，让学生估计完成作业用的小时数，而不是让学生回答作业负担是否过重。
- 只收集实际影响教学行为的反馈。如果一个问题的回答并不影响之后的课程教学，那就删掉这一题。
- 减轻学生填问卷的思考负担。例如能做成选择就不要填空，让学生估计完成作业的小时数，可以给出0到3、3到6、6到9小时的选项，而不是让学生填写一个具体数字。
- 可以找两三个学生试答问卷，看看学生是否理解问题的本意、填答是否容易，从而对问卷做一点修改。

反馈收集相关(非问卷形式):

- 考虑只回收教学团队能分析得了的数据量。例如，每周课前让十六分之一的同学填写预习学案，多了改不过来。
- 利用作业环节做自然的反馈，减轻学生负担。学生通过作业就把学习情况反馈给了老师。也可以在实验报告里请学生写写对作业的看法。
- 如果觉得长一些的文字反馈有用，可以列出一些问题，形成访谈提纲，用微信/邮件发给一些同学，或者线下聊一聊。
- 和多名同学们做午餐会、下午茶等交流的时候，也可以提前整理一些问题，方便同学们展开思路。缺点是会限制发散性。(可尝试搜索: 焦点小组)
- 对一些较大的改动，可以采取“测试”的方式。例如新的大作业，在假期或前半学期找同学试做。

反馈分析和使用相关：

- 注意学生所说和所做未必一致。作业环节如果有一些行为数据，可以仔细分析一下。
- 如果有可能，通过不同的反馈渠道对一些想法进行交叉验证。
- 如果问卷回收率不高，可以对不填写问卷的同学私聊联系（需要实名回收）。或者忽略不填写问卷的同学，因为他们主动放弃了让教学团队了解自己想法的权利。
- 努力让学生意识到，自己的反馈得到重视、对课程教学有所影响。但不一定占用课堂时间去讲，发公告就足够了。学生也会意识到潜移默化的教学改进。
- 教师需要判断，某个学生写的一段反馈，是个别的还是普遍的。数学证明里有孤证不立，现实社会里有“沉默的大多数”。（例如匿名社区的反馈常常是个别的）
- 接上条，如果有可能，对于个别的、实名的反馈做个别的回应。不要对个别的反馈做公开回应，这浪费了大多数人的时间。

课程团队管理/合作相关：

- 注重数据的保存和维护。不要因为助教人员变换而丢失往年数据。这样可以比较不同学期的反馈内容变化。
- 确保课程团队对于反馈数据的收集、解读和使用能达成共识。教师有时需要拍板。
- 可以积极利用外部资源，例如教师发展中心提供[中期学生反馈服务](https://www.cfd.tsinghua.edu.cn/fwxm/jszx/zqxsfk.htm), 或者和系课程调研委员会联系。

线下调研时，我们会把这些原则做成问卷, 请参与讨论的师生填写“赞同/不赞同”。

### 了解学生背景信息

在开展课程调研前，首先要对学生的背景信息有所了解（或有所假设）, 这不限于上面提到的“对课程质量的整体要求“。

- 同学们想在计算机系成为什么样的人？
- 同学们将来想深造和直接工作的比例如何？
- 同学们最想找到什么样的工作？对就业有什么想法？今年就业形势怎么样？
- 同学们对计算机领域的哪些细分方向更感兴趣？
- 同学们当前的整体课业压力如何?

这些问题, 对一门课程是否受欢迎, 会带来一定的影响。

例如方向A相关的必修课，对于想做方向B的同学，就可能感到“用不上”而打出低分。这时，如果你是这门必修课的教师，且了解到这一点，就可以尝试给同学们介绍未来方向A和方向B交叉研究的前景、以及方向B的高水平研究中方向A的知识可以发挥的作用。甚至可以设计一些与方向B交叉融合的讲座、作业环节。

如果整体课业压力已经偏大，那么课程在增加作业挑战度的时候，就要慎之又慎。

如果有一些你认为重要的信息实在无法从其他渠道获得，那么可以尝试把相关问题加到自己的课前问卷里。但也有很多信息已经被其他渠道调研过:

1. 校系团委、学生会、系课程调研委员会，都可能开展一些基础调研，可以向他们的相关负责人联系，获得一些数据/报告。
2. 通过社交媒体、私下聊天等方式和学生交流，对了解学生的精神面貌也有帮助，但要注意：乐于和教师交流的学生，不一定能代表其他的学生。
3. 也可以和辅导员等学生工作负责人交流，了解学生的普遍状态。
4. 教师之间讨论、教师和助教讨论，都可以获得一些关于当下学生的认知。但助教比课上的学生高出三四个年级，已经有可能和学生出现代沟，要小心这一点。

最终，你可能会获得一些“学生画像”（Personas），类似于“产品画像”。最好的状态是，当教学团队准备采取一些课程改进措施的时候，通过脑海中（或者写在文档里的）“学生画像”，你能对学生将来实际的反应预测个八九不离十。经验丰富的优秀教师通常拥有这个能力。

### 收集关于课堂教学 / 编程作业的具体反馈

**关于课堂教学**

课堂氛围、雨课堂答题都是在课堂上可以及时获得的反馈。课后也可以通过一些方式了解同学们对课堂的感受。

我们甚至可以在课前获得关于课堂教学的反馈：如果将课件（或单独编写预习学案）提前发放给部分学生，请他们反馈课件/学案的重难点，就可以在课上突出这些重点。

课程群的讨论和提问、同学对助教的线上线下提问，甚至作业的完成情况，都可以反映课堂教学的效果。

例如，作业中关于某个知识点的错误率很高，就要回顾课堂上是否没有把这个知识点讲清楚/讲透。

助教听课也是一种可能的反馈手段，但需要助教投入较多的时间，因此需要教学团队的权衡。

获得反馈之后，是否要在课堂上重复讲同学们理解困难的重难点？还是发一些文档？还是请助教安排习题课？这些都看情况而定。

如果能在助教精力允许的情况下每周安排习题课进行梳理，那么效果将是最好的。

（关于课堂教学、习题课的细致讨论将在之后章节进行）

**关于编程作业**

如果使用OJ、gitlab等平台来收取编程作业，那么就可以自然从平台获得大量数据。但这些数据只有经过分析之后才具有反馈的价值。有时间可以考虑写一些脚本，建立自动的数据分析管线。或者有可能的话，跟平台方联系，增加便于数据分析的特性，实现更高水平的教育数字化。

同学对作业提交的具体代码、实验报告也是价值很高的反馈：通过这些反馈，我们了解同学们对作业的完成情况，从而了解关于作业合理性的反馈。也可以考虑在实验报告里直接让同学写一些对这份作业的感受和意见，不少同学是愿意写的。

如果课程具有多个编程作业/编程作业有多个部分，不妨用这样的方式在问卷里问一些问题：“您最喜欢/讨厌的题目/作业模块是什么/哪些？为什么？”。当然，别忘了把各种作业题目/模块列成选项让同学们直接选。也可以问问“您花费最多时间的题目/作业模块/步骤”是什么。

关于作业本身出现错漏，表达不严谨、甚至难以完成的反馈，需要得到最高优先级的处理。甚至可以考虑给提供这类反馈的同学加分。

助教对编程作业开展答疑时，可以获得很多高质量的反馈，适当注意整理一下，会对改善作业质量有帮助。

关于作业延期的反馈也很常见。常常有同学私聊请求作业延期，有时候教师也会发布问卷询问大家是否延期。需要尽量避免的情况是“在最后一刻延期/在截止之后延期”：想一想，为了赶上作业deadline, 你已经放弃了一场考试的复习/错过了一场约会/熬夜到凌晨三点/代码写得很潦草，第二天醒来发现老师在群里说作业延期一个星期......这个时候你肯定有冲动给这门课的教评打最低分。如果要延期，至少让大多数同学有机会通过重新安排时间从延期中获益。

（关于设计编程作业与答疑的细致讨论将在之后章节进行）

### 收集分析课程反馈时，需要避开的误区/雷区

- 将学生当作“填数据的工具人”。我们希望学生通过提供反馈共同参与到课程建设/学习体验优化中。
- 如果反馈渠道本身不是教学活动，那么不要用分数作为激励。（或者说，不应当让学生通过填问卷获得平时分。）
- 问卷过长。可能会导致问卷回收量极小。建议通过试做，估计一个问卷用时写在问卷简介里，最好不超过10分钟。
- 问卷只包含大量的选择题/判断题/量表题。除非是安排答疑时间这种事务性的调研，建议至少包含一道开放性的文本题目, 学生可以讲讲自己的想法。
- 问题引导性过强。例如不要问“你是否觉得课堂讲授过快”，而要问“你在课上消化吸收到什么程度、哪些因素导致当堂吸收不好（选择或填空题）"
- 过于在乎极端数据。在大班课程中，统计学上必然出现离谱的反馈。如果不能过滤掉，就会导致反馈数据被污染。
- 学生不知道反馈渠道的存在。可以在第一节课梳理学生能提供反馈的相关渠道，或在课间/课后提醒学生填写问卷。
- 在和学生直接沟通时（一对一访谈、午餐会等），给学生过多的压力。尽量维持良好的讨论氛围，即使学生发言偏激，课程团队也要保持风度。
- 持续补充......
  
（线下研讨时，会有一个讨论话题：如何编写一份课前调研问卷？）

可参考: [How to increase course evaluation response rates: 10 do’s and 3 don’ts](https://www.uhd.edu/provost/teaching-learning-excellence/instructional-excellence/Documents/How%20to%20increase%20course%20evaluation%20response%20rates.pdf)

## D. 怎样得到可行的课程改进措施？/ 判断课程改进措施是否可行？

判断一项课程改进措施是否可行、得到一项可行的课程改进措施，是两个不同的问题，有一点NP=P？的意思。

首先我们看看课程改进最早的想法可能从哪里来(列表持续更新):

1. 从上述课程反馈中总结出来。对应学生反馈的课程痛点进行优化，或者对学生提出来的改进意见进行细化落地。学生课程调研委员会也可能会提供一些课改想法。
2. 国家/学校政策导向。例如近年一些老师会参与教育部推动的“课程思政”改革或学校推动的“提升课程挑战度”改革。
3. 与其他课程改革的协同。例如某门课程的改革需要一些先修知识，可以去联络先修课程的教师共同改革。
4. 和他人交流时产生想法。例如在教学工作坊和其他教师交流教学的想法、和企业界交流对学生能力的需求等，或者教师和助教讨论获得一些想法。
5. 从计算机专业科研中迁移过来。例如在科研中发现一块很有用的知识/一些有用的工具，想办法加入到课程中来。
6. 从教育研究中迁移过来。例如读了SIGCSE/ICER/《计算机教育》某篇文章觉得不错，把做法拿到课程中来。或者读教育专著产生新想法。
7. 模仿其他课程。例如把自己的课程和stanford、MIT的同类课程比较一下，容易发现不少做法不同的地方，从中就可以找到改进课程的思路。
8. 迭代完善。例如对上学期增加的新内容/新作业认为不够完善需要打磨。
9. 涌现。了解足够多的课程教学做法、学生反馈信息、和课程教学有关无关的知识后，花费一些时间琢磨怎么改进教学后，脑子里突然冒出来的想法。如同LLM的涌现一样不可预测。

有时候，课程改进的初步想法不是太少，而是太多。但并不是每一个想法都能变成可行的课程改进措施/方案。即使所有想法都可行，也很少有资源在一个学期内将所有想法全部圆满实现，往往只能选择最重要、最可行的几项来开展。

初步看似可行的课程改进措施/方案，在实际实施时又会遇到很多意想不到的情况。

对一个初步的课程改进想法或课程改进方案，想要提升其可行性，就需要尽可能地多做调研、讨论、收集反馈。但也没时间无止境地做可行性分析，有时只能在实际的课程里先一点点做起来。

无论如何，对于自己拿不准的课程剧烈改动，不要一下子就在课程里完全实施，尽量找一些逐步将其纳入课程的方法，时刻注意学生对这些变化的反馈。

或者说，要设想最坏的场景：在最糟糕的情况下，这个课程改进方案会导致什么后果? 有什么应对方法吗？ 在后果基本可控的情况下，也可以大胆一些。
